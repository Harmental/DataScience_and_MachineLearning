{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/10-gen-ai/Week_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg25MkDgcADy"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/10-gen-ai/Week_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLbG_J_EdcyH"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install langchain-openai\n",
        "!pip install openai\n",
        "!pip install wikipedia\n",
        "!pip install chromadb\n",
        "!pip install tiktoken\n",
        "!pip install pypdf\n",
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NCfM18ZRl8L"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wikipedia\n",
        "import urllib.request\n",
        "import bs4 as bs\n",
        "import os\n",
        "\n",
        "#import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# import Langchain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI, ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.chains import create_tagging_chain, create_tagging_chain_pydantic\n",
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5WgfVqRRl8N"
      },
      "source": [
        "# Generative AI\n",
        "\n",
        "<img src='https://images.unsplash.com/photo-1686191568035-db49125b65c6?auto=format&fit=crop&q=80&w=2940&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D' width=\"450\">\n",
        "\n",
        "Credit: [Mojahid Mottakin](https://unsplash.com/@iammottakin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onO46LysT2dh"
      },
      "source": [
        "## Content\n",
        "\n",
        "The goal of this walkthrough is to provide you with insights on [Generative AI](https://en.wikipedia.org/wiki/Generative_artificial_intelligence). Generative AI refers to artificial intelligence systems that can create new and original content, such as text, images, or music, without direct human input.\n",
        "\n",
        "We will first see some applications that we can have with GenAI and the text. We will also see that using GenAI can be costly and we will finally try to fine tune a model.\n",
        "\n",
        "- [First steps with LangChain and OpenAI](#First-steps)\n",
        "    - [Claculate the cost](#Cost)\n",
        "- [Text Summarization](#Text-Summarization)\n",
        "- [Sentiment analysis](#Sentiment-analysis)\n",
        "- [Text embedding](#Text-embedding)\n",
        "- [Fine-tuning](#Fine-tuning)\n",
        "- [Your turn!](#exercices)\n",
        "    - [Prompt](#prompting)\n",
        "    - [Summarizing](#Summarizing)\n",
        "    - [Sentiment analysis](#Sentiment-analysis-ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv1T75j9YpS4"
      },
      "source": [
        "## First steps with LangChain and OpenAI\n",
        "During this exercise session, we will be using the [OpenAI](https://platform.openai.com/docs/api-reference) API with different libraries.\n",
        "First we will need to setup the apikey and some of the librairies.\n",
        "\n",
        "\n",
        "We will also use the [Langchain](https://python.langchain.com/docs/get_started/introduction) library for the prompting and the text applications.\n",
        "\n",
        "First, we will define the API key. You can find how to create an API key with your account in this document : [Guide-API-Key-OpenAi](https://github.com/michalis0/DataScience_and_MachineLearning/blob/master/10-gen-ai/Guide-API-Key-OpenAI.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNtXBIJGbB1Q"
      },
      "outputs": [],
      "source": [
        "# define the openAI API key\n",
        "os.environ['OPENAI_API_KEY'] = 'YOUR OPENAI API KEY'\n",
        "print(os.getenv('OPENAI_API_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_A3akTUhHCH"
      },
      "source": [
        "To try the key, let's use OpenAI like we would use ChatGPT.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aFDzxmgYsdD"
      },
      "outputs": [],
      "source": [
        "# define the chat and try it with a simple message\n",
        "chat_model  = OpenAI()\n",
        "\n",
        "print(chat_model.invoke(\"Hi! How are you?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmORZnjrl15m"
      },
      "source": [
        "You can also use it differently as it is shown in the two following examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTeJiGm6iNtl"
      },
      "outputs": [],
      "source": [
        "text = \"What would be a good startup name for startup from a student who just graduated from a degree in Information Systems and Digital Innovation?\"\n",
        "\n",
        "print(chat_model.invoke(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXde7hOAiaVw"
      },
      "outputs": [],
      "source": [
        "text = \"What would be a good startup name for startup from a student who just graduated from a degree in Information Systems and Digital Innovation?\"\n",
        "messages = [HumanMessage(content=text)]\n",
        "\n",
        "print(chat_model.invoke(messages))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YqxMiZcmOxL"
      },
      "source": [
        "With Langchain, you can directly pass specifications for a prompt by using the ```PromptTemplate``` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bxWPF9mkoyI"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate.from_template(\"What is a good name for a startup that works in {field}?\")\n",
        "prompt.format(field=\"Information Systems and Digital Innovation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti0RqVq8_Fzc"
      },
      "source": [
        "### Calculate the cost\n",
        "Everything has a cost and the chatGPT API is not free. It depends on how many tokens we are giving to the API. You can have the pricing [here](https://openai.com/api/pricing/).\n",
        "\n",
        "To give you an idea of the costs, calculate the price of using the GPT-4 model with a document that contains 86'000 tokens and you want a summary of 1'000 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPrLNLh69NNw"
      },
      "outputs": [],
      "source": [
        "# Your turn!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Your turn: generate a random solution for your project!\n",
        "\n",
        "We have seen tha the leaderboard has been quite silent during last week, unfortunately! Therefore, to spice things up a little bit, we ask you to use the OpenAI chatGPT model in order to generate a code script for you. The code script should use pandas in order to generate a dataframe that has the same format as the `sample_submission.csv` file in kaggle. Try to run the code given by the chatGPT model in this notebook and save the generated dataframe as a csv file. Submit this csv to kaggle to get you place in the leaderboard:).\n",
        "\n",
        "Remark 1: We have 7838 users and 15109 items in the project dataset.\n",
        "\n",
        "Remark 2: You should not expect to get a decent score with this submission!"
      ],
      "metadata": {
        "id": "Kxv-807xl2sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your turn!\n",
        "\n",
        "text = \"\"\"\n",
        "Type yur prompt to chatGPT here!\n",
        "\"\"\"\n",
        "\n",
        "print(chat_model.invoke(text))"
      ],
      "metadata": {
        "id": "UqCTEa-6nhGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pI-k5OMvn95"
      },
      "source": [
        "## Text Summarization\n",
        "GenerativeAI can be very useful to summarize data. We will continue to use [Langchain](https://python.langchain.com/docs/use_cases/summarization) for our implementation. We will try to summarize the Wikipedia page of [*Information System*](https://en.wikipedia.org/wiki/Information_system). We will first load the text, the model [gpt-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5#gpt-3-5-turbo), which allow us to have 16k tokens, and the chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyaUfkbNvpvp"
      },
      "outputs": [],
      "source": [
        "# load the text\n",
        "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Information_system\")\n",
        "docs = loader.load()\n",
        "\n",
        "# load the model and the chain\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
        "chain = load_summarize_chain(llm, chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl9w98ej_Nhj"
      },
      "source": [
        "### Calculate the cost\n",
        "Using openAI API is not free. You can calculate the cost of your model like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBCYdOpk_gIT"
      },
      "outputs": [],
      "source": [
        "#get the costs\n",
        "with get_openai_callback() as cb:\n",
        "  result = chain.run(docs)\n",
        "  print(cb)\n",
        "  display(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsQoyYkH1lwM"
      },
      "source": [
        "## Sentiment analysis\n",
        "\n",
        "By using Langchain, we can also classify the text. You can give different categories to the model and it will try to classify the sentence. For example, we will do a sentiment analysis and we will try to recognize in which language it is written.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI6x1BhRJPHb"
      },
      "outputs": [],
      "source": [
        "# Schema\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"sentiment\": {\n",
        "            \"type\": \"string\",\n",
        "            \"enum\":[\"positive\", \"neutral\", \"negative\"],\n",
        "        },\n",
        "        \"language\": {\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"spanish\", \"english\", \"french\", \"german\", \"italian\"],\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"sentiment\", \"language\"],\n",
        "}\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "chain = create_tagging_chain(schema, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlb1g9BWO5KS"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "input = \"I love dogs!\"\n",
        "\n",
        "chain.run(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_SUKEgOSnOD"
      },
      "source": [
        "## Text embedding\n",
        "LangChain is also useful for text embedding. You can see the different models [here](https://python.langchain.com/docs/integrations/text_embedding/). You can have a look at the natural language processing class if you don't remeber why text embedding is important.\n",
        "\n",
        "You can either do the text embedding for a list of texts or a single piece of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AwioZxzZz4W"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55i2zcA2YW3s"
      },
      "outputs": [],
      "source": [
        "#embeding a single query\n",
        "text = \"This is a test document.\"\n",
        "query_result = embeddings.embed_query(text)\n",
        "query_result[:5]\n",
        "len(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w89IGJ2IZ2eo"
      },
      "outputs": [],
      "source": [
        "#embeding a list of texts\n",
        "embedds = embeddings.embed_documents(\n",
        "    [\n",
        "        \"Hi there!\",\n",
        "        \"Oh, hello!\",\n",
        "        \"What's your name?\",\n",
        "        \"My friends call me World\",\n",
        "        \"Hello World!\"\n",
        "    ]\n",
        ")\n",
        "len(embedds), len(embedds[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ-TviJxmMsS"
      },
      "source": [
        "## Fine-tuning\n",
        "\n",
        "Fine-tuning refers to the process of taking a pre-trained model (like chatGPT) and further training it on a specific task or dataset to improve its performance on that particular task. Instead of training a model from scratch, which can be computationally expensive and time-consuming, fine-tuning leverages the knowledge and features learned by a model on a large and diverse dataset.\n",
        "\n",
        "You can have a more detailed article [here](https://medium.com/@dataoilst.info/fine-tuning-langchain-llm-applications-a-technical-perspective-part-1-4b4c552ab557).\n",
        "\n",
        "For now, we will use the previous text and try to ask the model a question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F82FIQoZatwK"
      },
      "outputs": [],
      "source": [
        "#processing the document\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(docs)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = FAISS.from_documents(texts, embeddings)\n",
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZimOCk4a9dD"
      },
      "outputs": [],
      "source": [
        "#asking the question\n",
        "retrieved_docs = retriever.invoke(\n",
        "    \"What is an information system?\"\n",
        ")\n",
        "print(retrieved_docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU4dqJmMeRYO"
      },
      "source": [
        "We can see that the model is simply giving us the parts where information system is mentionned. Therfore, the model is not very useful. You can however go a bit further if you wish to integrate it better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9owDlwBaLXp0"
      },
      "source": [
        "## Your turn!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDbF60XZevym"
      },
      "source": [
        "### Prompt\n",
        "Create a prompt to ask chatGPT some project ideas for a Data Science and Machine Learning class. Try to apply some rules of [prompt engineering](https://www.datacamp.com/tutorial/a-beginners-guide-to-chatgpt-prompt-engineering)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFZ5t75WfMXr"
      },
      "outputs": [],
      "source": [
        "# Your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAG2jjy_wGhh"
      },
      "source": [
        "### Summarizing\n",
        "\n",
        "You will now try to summarize one of your lesson and print how much it costed by using the model ```gpt-3.5-turbo```. You might want to look at the package ```PyPDFLoader``` in order to load your pdf.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAQQxguTyI9i"
      },
      "outputs": [],
      "source": [
        "# Your code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPPhytTFRQNz"
      },
      "source": [
        "### Sentiment analysis\n",
        "Try to classify this sentence: ```J'aime l'intelligence artificielle.```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpKnsJ1BRhR7"
      },
      "outputs": [],
      "source": [
        "# Your code\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}